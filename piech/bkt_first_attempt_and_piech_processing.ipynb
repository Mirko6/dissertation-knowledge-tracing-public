{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from main_package.utils import data_path_to_abs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"piech/train_original\"\n",
    "test_data = \"piech/test_original\"\n",
    "\n",
    "def read_sessions(filename):\n",
    "    f = open(data_path_to_abs_path(filename))\n",
    "    sessions = []\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        num_records = int(line.strip())\n",
    "        skills = np.array(f.readline().strip().split(\",\")[:-1], dtype=int)\n",
    "        answers = np.array(f.readline().strip().split(\",\")[:-1], dtype=int)\n",
    "        if num_records > 1:\n",
    "            sessions.append((skills, answers))\n",
    "    f.close()\n",
    "    return sessions\n",
    "\n",
    "sessions_train = read_sessions(train_data)\n",
    "sessions_test = read_sessions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is for making the test dataset available in other format\n",
    "def from_sessions_to_df(sessions, name):\n",
    "    skills, answers = sessions[0]\n",
    "    student_id = 0\n",
    "    students = np.zeros((len(skills)), dtype=int)\n",
    "    for session in sessions[1:]:\n",
    "        student_id += 1\n",
    "        students = np.append(students, [student_id]*len(session[0]))\n",
    "        skills = np.append(skills, session[0])\n",
    "        answers = np.append(answers, session[1])\n",
    "    \n",
    "    df = pd.DataFrame({\"user_id\": students, \"skill_id\": skills, \"correct\": answers})\n",
    "    #df.to_csv(name, index=False)\n",
    "    return df\n",
    "\n",
    "df_test_piech = from_sessions_to_df(sessions_test, \"piech_test_df_format.csv\")\n",
    "df_train_piech = from_sessions_to_df(sessions_train, \"piech_train_df_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train + test dataset length: 525425\n",
      "training dataset length: 407880\n",
      "testing dataset length: 117545\n",
      "test ratio: 0.223714136175477\n"
     ]
    }
   ],
   "source": [
    "print(f\"train + test dataset length: {len(df_train_piech)+len(df_test_piech)}\")\n",
    "print(f\"training dataset length: {len(df_train_piech)}\")\n",
    "print(f\"testing dataset length: {len(df_test_piech)}\")\n",
    "print(f\"test ratio: {len(df_test_piech) / (len(df_train_piech)+len(df_test_piech))}\")\n",
    "df_train_piech.to_csv(\"piech_all_df_format.csv\", index=False)\n",
    "df_test_piech.to_csv(\"piech_all_df_format.csv\", index=False, header=False, mode='a')\n",
    "df_all = pd.read_csv(\"piech_all_df_format.csv\")\n",
    "df_all.to_csv(\"piech_all_df_format.csv\", index=True, index_label='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.676954\n",
      "0    0.323046\n",
      "Name: correct, dtype: float64\n",
      "1    0.688451\n",
      "0    0.311549\n",
      "Name: correct, dtype: float64\n",
      "1    0.679526\n",
      "0    0.320474\n",
      "Name: correct, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_train_piech['correct'].value_counts(normalize=True))\n",
    "print(df_test_piech['correct'].value_counts(normalize=True))\n",
    "print(df_all['correct'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkt_single_skill(session, p_L0: float, p_G: float, p_S: float, p_T: float):\n",
    "    skill, right = session\n",
    "    assert len(skill) == len(right)\n",
    "    n = len(skill)\n",
    "    current_skill = -1\n",
    "    assert current_skill not in skill\n",
    "    p_prior, p_prior_cond, p_posterior = 0, 0, 0 #PLn-1, PLn-1|answer, PLn\n",
    "    posteriors = np.empty((n), dtype=np.float64)\n",
    "    priors = np.empty((n), dtype=np.float64)\n",
    "    squared_sum_residuals = 0\n",
    "    for i in range(n):\n",
    "        if skill[i] == current_skill:\n",
    "            p_prior = posteriors[i-1]\n",
    "        else:\n",
    "            p_prior = p_L0\n",
    "            current_skill = skill[i]\n",
    "        priors[i] = p_prior\n",
    "\n",
    "        if right[i]:\n",
    "            p_did_not_slip_and_knew = (1 - p_S) * p_prior\n",
    "            p_guessed_and_did_not_know = p_G * (1 - p_prior)\n",
    "            p_prior_cond = p_did_not_slip_and_knew / (p_did_not_slip_and_knew + p_guessed_and_did_not_know)\n",
    "        else:\n",
    "            p_slipped_and_knew = p_S * p_prior\n",
    "            p_did_not_guess_and_did_not_know = (1 - p_G) * (1 - p_prior)\n",
    "            p_prior_cond = p_slipped_and_knew / (p_slipped_and_knew + p_did_not_guess_and_did_not_know)\n",
    "        \n",
    "        p_posterior = p_prior_cond + p_T * (1 - p_prior_cond)\n",
    "        posteriors[i] = p_posterior\n",
    "\n",
    "        likelihood_correct = p_prior * (1 - p_S) + (1 - p_prior) * p_G\n",
    "        squared_sum_residuals += (right[i] - likelihood_correct)**2\n",
    "    return priors, squared_sum_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkt_minimize(params, sessions):\n",
    "    p_L0, p_G, p_S, p_T = params\n",
    "    #print(f\"p_L0: {p_L0}, p_G: {p_G}, p_S: {p_S}, p_T: {p_T}\")\n",
    "    result = 0\n",
    "    for session in sessions:\n",
    "        _, ssr = bkt_single_skill(session, p_L0, p_G, p_S, p_T)\n",
    "        result += ssr\n",
    "    #print(f\"squared_sum_residuals: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_L0 = 0.5504063365919529\n",
      "p_G = 0.3\n",
      "p_S = 0.0999999975569658\n",
      "p_T = 0.06302321901515896\n",
      "      fun: 76382.33392676056\n",
      " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 1.75667809e+02, -2.91853747e+06, -3.08436575e+04, -2.79699452e+02])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 310\n",
      "      nit: 15\n",
      "     njev: 62\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.55040634, 0.3       , 0.1       , 0.06302322])\n"
     ]
    }
   ],
   "source": [
    "initial_guess = [0.4, 0.2, 0.08, 0.1] #p_L0, p_G, p_S, p_T\n",
    "dx = 0.0001\n",
    "bounds = [(dx, 1-dx), (dx, 0.3), (dx, 0.1), (dx, 1-dx)]\n",
    "result = minimize(bkt_minimize, initial_guess, args=sessions_train, bounds=bounds, method='L-BFGS-B')\n",
    "#method L-BFGS-B is the default for bounded minimization\n",
    "print(f\"p_L0 = {result.x[0]}\\np_G = {result.x[1]}\\np_S = {result.x[2]}\\np_T = {result.x[3]}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model fit for test :) - hups\n",
    "p_L0 = 0.5641198789451226\n",
    "p_G = 0.3\n",
    "p_S= 0.09999998796996834\n",
    "p_T= 0.056647248212908334\n",
    "\n",
    "newer model fit for train\n",
    "p_L0 = 0.5504063365919529\n",
    "p_G = 0.3\n",
    "p_S = 0.0999999975569658\n",
    "p_T = 0.06302321901515896\n",
    "\n",
    "original model fit for train\n",
    "p_L0 = 0.5497157313235409\n",
    "p_G = 0.3\n",
    "p_S = 0.0999999919596138\n",
    "p_T = 0.0631258533486059\n",
    "\"\"\"\n",
    "\n",
    "# model fit for train\n",
    "p_L0 = 0.5504063365919529\n",
    "p_G = 0.3\n",
    "p_S = 0.0999999975569658\n",
    "p_T = 0.06302321901515896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 117545\n",
      "squared sum of residuals: 21684.46449641108\n",
      "auc: 0.7295786468978473\n"
     ]
    }
   ],
   "source": [
    "prediction, ssr_total = bkt_single_skill(sessions_test[0], p_L0, p_G, p_S, p_T)\n",
    "correct = np.copy(sessions_test[0][1])\n",
    "for session in sessions_test[1:]:\n",
    "    estimate, ssr = bkt_single_skill(session, p_L0, p_G, p_S, p_T)\n",
    "    correct = np.append(correct, session[1])\n",
    "    prediction = np.append(prediction, estimate)\n",
    "    ssr_total += ssr\n",
    "print(f\"number of records: {len(prediction)}\")\n",
    "print(f\"squared sum of residuals: {ssr_total}\")\n",
    "print(f\"auc: {roc_auc_score(correct, prediction)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
